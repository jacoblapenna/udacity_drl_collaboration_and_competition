# Collaboration and Control (Tennis)

This project solves the Udacity tennis environment. It uses a neural network defined in [model.py](/model.py). The Agent class implements all the code needed to train the model given specific instantiation hyperparameters. The report details the specific architecture and how the model was trained in various ways.

Follow the instructions in the [Tennis](/Tennis.ipynb) notebook to install the dependencies. Due to the inability to find the correct environment online, the workspace was used to complete this project. For this reason, the environment path within the Agent class defaults to the recommended environment path.

To train an agent, simply instantiate it with the desired hyperparameters and call `agent.train_agent()` with the desired episode max count and solution threshold. The session stores the scores for each actor for each episode, along with the hyperperameters used for that training session. This information is store in the SQLite database for later comparison in the [Report][\Report.ipynb].

NOTE: if running outside the workpace, agent instantiation must use the correct environment path. This is the path where the Unity environment is located. As mentioned, the project is so outdated I could not find the correct Unity dependencies online. This means I could only run the project within the workspace with the older Unity dependencies and builds. On my system, the provided environment build was too old for the available Unity downloads. For this reason, only a basic README is needed, as it is expected that this project is ran on the provided Udacity workspace virtual machine with all dependencies pre-installed and the environment path already setup.